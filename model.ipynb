{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(29)\n",
    "\n",
    "from flask import Flask, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df(requestData):\n",
    "  df = pd.DataFrame(to_array(requestData), columns=[\n",
    "    'heading',\n",
    "    'speed',\n",
    "    'fuel_consumption',\n",
    "    'wind',\n",
    "    'rel_wind_dir',\n",
    "    'gust',\n",
    "    'waves_height',\n",
    "    'rel_waves_dir',\n",
    "    'waves_period',\n",
    "    'wwaves_height',\n",
    "    'rel_wwaves_dir',\n",
    "    'wwaves_period',\n",
    "    'swell1_height',\n",
    "    'rel_swell1_dir',\n",
    "    'swell1_period',\n",
    "    'swell2_height',\n",
    "    'rel_swell2_dir',\n",
    "    'swell2_period',\n",
    "    'ocean_current_vel',\n",
    "    'rel_ocean_current_dir'\n",
    "  ])\n",
    "\n",
    "  # Delete initial row containing only zeros\n",
    "  df = df.drop(0)\n",
    "\n",
    "  return df\n",
    "  \n",
    "\n",
    "def to_array(requestData):\n",
    "  data = np.zeros(20)\n",
    "\n",
    "  for dp in requestData:\n",
    "    dp_data = np.array([])\n",
    "    # Define vessel heading in data point\n",
    "    heading = dp['vessel']['heading']\n",
    "    \n",
    "    dp_data = np.append(dp_data, heading)\n",
    "    dp_data = np.append(dp_data, dp['vessel']['speed'])\n",
    "    dp_data = np.append(dp_data, dp['vessel']['fuelConsumption']['drift'])\n",
    "    # Calculate wind speed\n",
    "    dp_data = np.append(dp_data, math.sqrt(dp['weather']['windU'] ** 2 + dp['weather']['windV'] ** 2))\n",
    "    # Calculate wind direction and then wind direction relative to ship heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      calculate_dir(\n",
    "        dp['weather']['windU'],\n",
    "        dp['weather']['windV']\n",
    "      )\n",
    "    ))\n",
    "    dp_data = np.append(dp_data, dp['weather']['gust'])\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['waves']['wavesHeight'])\n",
    "    # Calculate waves direction relative to vessel heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      dp['marineWeather']['waves']['wavesDirection']\n",
    "    ))\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['waves']['wavesPeriod'])\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['wwaves']['wwavesHeight'])\n",
    "    # Calculate wind waves direction relative to vessel heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      dp['marineWeather']['wwaves']['wwavesDirection']\n",
    "    ))\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['wwaves']['wwavesPeriod'])\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['swellWaves']['swell1Height'])\n",
    "    # Calculate class 1 swell waves direction relative to vessel heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      dp['marineWeather']['swellWaves']['swell1Direction']\n",
    "    ))\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['swellWaves']['swell1Period'])\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['swellWaves']['swell2Height'])\n",
    "    # Calculate class 2 swell waves direction relative to vessel heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      dp['marineWeather']['swellWaves']['swell2Direction']\n",
    "    ))\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['swellWaves']['swell2Period'])\n",
    "    dp_data = np.append(dp_data, dp['marineWeather']['oceanCurrentVelocity'])\n",
    "    # Calculate ocean current direction relative to vessel heading\n",
    "    dp_data = np.append(dp_data, calculate_rel_dir(\n",
    "      heading,\n",
    "      dp['marineWeather']['oceanCurrentDirection']\n",
    "    ))\n",
    "\n",
    "    data = np.vstack([data, dp_data])\n",
    "\n",
    "  return data\n",
    "\n",
    "def calculate_dir(u, v):\n",
    "  refU = 0\n",
    "  refV = 1\n",
    "\n",
    "  cos = (refU * u + refV * v) / (math.sqrt(refU ** 2 + refV ** 2) * math.sqrt(u ** 2 + v ** 2))\n",
    "  rad = math.acos(cos)\n",
    "  deg = rad * (180 / math.pi)\n",
    "\n",
    "  return deg\n",
    "\n",
    "\n",
    "def calculate_rel_dir(heading, param):\n",
    "  param_toward = (param + 180) % 360\n",
    "  relative_param = (param_toward - heading + 360) % 360\n",
    "\n",
    "  return relative_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df: pd.DataFrame):\n",
    "  train_set, test_set = train_test_split(df, test_size=0.2, random_state=29)\n",
    "\n",
    "  data = train_set.drop('fuel_consumption', axis=1)\n",
    "  data_labels = train_set['fuel_consumption'].copy()\n",
    "\n",
    "  # Scale data so that all attributes range from 0 to 1\n",
    "  scaler = MinMaxScaler()\n",
    "  model = scaler.fit(data)\n",
    "  data_scaled = model.transform(data)\n",
    "\n",
    "  # # Linear regression\n",
    "  # print('LINEAR REGRESSION:')\n",
    "\n",
    "  # lin_reg = LinearRegression()\n",
    "  # lin_reg.fit(data_scaled, data_labels)\n",
    "\n",
    "  # some_data = data.iloc[:5]\n",
    "  # some_labels = data_labels.iloc[:5]\n",
    "  # some_data_scaled = model.transform(some_data)\n",
    "\n",
    "  # print ('Predictions:', lin_reg.predict(some_data_scaled))\n",
    "  # print ('Labels:', list(some_labels))\n",
    "\n",
    "  # # RMSE of linear regression\n",
    "  # data_predictions = lin_reg.predict(data_scaled)\n",
    "  # lin_mse = mean_squared_error(data_labels, data_predictions)\n",
    "  # lin_rsme = np.sqrt(lin_mse)\n",
    "\n",
    "  # print('Root mean squared error:', lin_rsme)\n",
    "\n",
    "  # # Validation of linear regression\n",
    "  # lin_scores = cross_val_score(lin_reg, data_scaled, data_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "  # lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "  # display_scores(lin_rmse_scores)\n",
    "\n",
    "  # # Decision tree regression\n",
    "  # print('DECISION TREE REGRESSION:')\n",
    "\n",
    "  # tree_reg = DecisionTreeRegressor(random_state=29)\n",
    "  # tree_reg.fit(data_scaled, data_labels)\n",
    "\n",
    "  # # RMSE of decision tree regression\n",
    "  # data_predictions = tree_reg.predict(data_scaled)\n",
    "  # tree_mse = mean_squared_error(data_labels, data_predictions)\n",
    "  # tree_rmse = np.sqrt(tree_mse)\n",
    "\n",
    "  # print('Root mean squared error:', tree_rmse)\n",
    "\n",
    "  # # Validation of decision tree regression\n",
    "  # tree_scores = cross_val_score(tree_reg, data_scaled, data_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "  # tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "\n",
    "  # display_scores(tree_rmse_scores)\n",
    "\n",
    "  # Random forest regression\n",
    "  # print('RANDOM FOREST REGRESSION:')\n",
    "\n",
    "  forest_reg = RandomForestRegressor(max_features=10 , n_estimators=31, random_state=29)\n",
    "  forest_reg.fit(data_scaled, data_labels)\n",
    "\n",
    "  # # RMSE of random forest regression\n",
    "  # data_predictions = forest_reg.predict(data_scaled)\n",
    "  # forest_mse = mean_squared_error(data_labels, data_predictions)\n",
    "  # forest_rmse = np.sqrt(forest_mse)\n",
    "\n",
    "  # print('Root mean squared error:', forest_rmse)\n",
    "\n",
    "  # # Validation of random forest regression\n",
    "  # forest_scores = cross_val_score(forest_reg, data_scaled, data_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "  # forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "  # display_scores(forest_rmse_scores)\n",
    "\n",
    "  # # AdaBoost regression\n",
    "  # print('ADABOOST REGRESSION:')\n",
    "\n",
    "  # ada_reg = AdaBoostRegressor(n_estimators=100, random_state=29)\n",
    "  # ada_reg.fit(data_scaled, data_labels)\n",
    "\n",
    "  # # RMSE of AdaBoost regression\n",
    "  # data_predictions = ada_reg.predict(data_scaled)\n",
    "  # ada_mse = mean_squared_error(data_labels, data_predictions)\n",
    "  # ada_rmse = np.sqrt(ada_mse)\n",
    "\n",
    "  # print('Root mean squared error:', ada_rmse)\n",
    "\n",
    "  # # Validation of AdaBoost regression\n",
    "  # ada_scores = cross_val_score(ada_reg, data_scaled, data_labels, scoring='neg_mean_squared_error', cv=10)\n",
    "  # ada_rmse_scores = np.sqrt(-ada_scores)\n",
    "\n",
    "  # display_scores(ada_rmse_scores)\n",
    "\n",
    "  # # Hyperparameter tuning of random forest regression using grid search\n",
    "  # param_grid = [\n",
    "  #   {'n_estimators': [31], 'max_features': [10]}\n",
    "  # ]\n",
    "\n",
    "  # grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "  # grid_search.fit(data_scaled, data_labels)\n",
    "\n",
    "  # print(grid_search.best_params_)\n",
    "\n",
    "  # cvres = grid_search.cv_results_\n",
    "  # for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "  #   print(np.sqrt(-mean_score), params)\n",
    "\n",
    "  X_test = test_set.drop('fuel_consumption', axis=1)\n",
    "  y_test = test_set['fuel_consumption'].copy()\n",
    "\n",
    "  X_test_scaled = model.transform(X_test)\n",
    "  predictions = forest_reg.predict(X_test_scaled)\n",
    "\n",
    "  mse = mean_squared_error(y_test, predictions)\n",
    "  rmse = np.sqrt(mse)\n",
    "\n",
    "  print(rmse)\n",
    "\n",
    "def display_scores(scores):\n",
    "  print('Scores:', scores)\n",
    "  print('Mean:', scores.mean())\n",
    "  print('Standard deviation:', scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/train', methods=['POST'])\n",
    "def train():\n",
    "  data = request.json\n",
    "  df = construct_df(data)\n",
    "  train_model(df)\n",
    "  return '', 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
